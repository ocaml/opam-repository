opam-version: "2.0"
authors: "Francois Berenger"
maintainer: "unixjunkie@sdf.org"
homepage: "https://github.com/UnixJunkie/pardi"
bug-reports: "https://github.com/UnixJunkie/pardi/issues"
dev-repo: "git+https://github.com/UnixJunkie/pardi.git"
license: "GPL-1.0-or-later"
build: ["dune" "build" "-p" name "-j" jobs]
depends: [
  "dune" {>= "1.11"}
  "batteries"
  "dolog" {>= "4.0.0"}
  "parany" {>= "11.0.0"}
  "minicli" {>= "5.0.0"}
  "ocaml" {>= "4.05.0"}
## only the dev. version needs those
# "lz4"
# "cryptokit"
# "zmq" {>= "5.0.0"}
]
synopsis: "Parallel execution of command lines, pardi!"
description: """
Almost like GNU parallel; just better.

Pardi pushes further the point at which you have to use a supercomputer.
Alternatively, it can be used on a supercomputer to make life in there
much more fun and productive.

Put back the fun into computing: use pardi!

usage:
pardi ...
  {-i|--input} <file>: where to read from
  {-o|--output} <file>: where to write to (default=stdout)
  [-s|--shell]: only shell commands in input file
  [{-n|--nprocs} <int>]: max jobs in parallel (default=all cores)
  [{-c|--chunks} <int>]: how many chunks per job (default=1)
  [{-d|--demux} {l|b:<int>|r:<regexp>|s:<string>}]: how to cut input 
  file into chunks (line/bytes/regexp/sep_line; default=line)
  {-w|--work} <string>: command to execute on each chunk
  %IN and %OUT are special tokens
  [{-m|--mux} {c|n}]: how to mux job results in output file
  (cat/null; default=cat)
  [{-ie|--input-ext} <string>]: append file extension to work input files
  [{-oe|--output-ext} <string>]: append file extension to work output files
  [{-p|--preserve}]: mux results while preserving input order
"""
url {
  src: "https://github.com/UnixJunkie/pardi/archive/v3.2.2.tar.gz"
  checksum: "md5=0fc687f48a2a34973d414994618dea19"
}
